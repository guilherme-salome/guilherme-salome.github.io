{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [pandas](https://pandas.pydata.org) package provides very efficient data structures and tools for analyzing data.\n",
    "There are two basic data types created by pandas: [`Series`](https://pandas.pydata.org/pandas-docs/stable/reference/series.html) and [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html).\n",
    "The `Series` class is built to store a column of data.\n",
    "That is, one characteristic and multiple observations.\n",
    "The `DataFrame` class is built to store several columns of related data.\n",
    "We will learn how to work with both classes.\n",
    "Pandas is built-on top of NumPy, and there are several other packages that rely on Pandas for data management.\n",
    "Later, we will work with the [Statsmodels](https://www.statsmodels.org/stable/index.html) package, which provides functions for statistical estimation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Install\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will install Pandas, but also two other packages, Statsmodels and [Requests](https://2.python-requests.org/en/master/).\n",
    "On the **terminal**, execute:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests\n",
    "pip install pandas\n",
    "pip install statsmodels==0.10.0rc2 --pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third line in the code above is to install the newest version of Statsmodels that has not yet been fully released.\n",
    "We need to do so, because the currently released version has some incompatibility issues with the most recent SciPy.\n",
    "If you are having issues with the installation process check [the pandas install page](https://pandas.pydata.org/pandas-docs/stable/install.html) or the [statsmodels install page](https://www.statsmodels.org/stable/install.html).\n",
    "\n",
    "Pandas should now be available under the `pandas` namespace.\n",
    "Just like with NumPy, Pandas is often imported as `pd`.\n",
    "Test if `pandas` is working properly on your computer:\n",
    "\n",
    "-   Start the Python REPL and do `import pandas`;\n",
    "-   If it is imported, then you are good to go.\n",
    "\n",
    "If you see an error when importing pandas, see [this discussion page](https://github.com/pandas-dev/pandas/issues/27532) and [this page](https://github.com/pyenv/pyenv/wiki/Common-build-problems) on how to fix the issue.\n",
    "Alternatively, uninstall pandas with `pip uninstall pandas` and install the previous version with `pip install pandas==0.24`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a Pandas Series.\n",
    "The Series object is like a single column of a spreadsheet.\n",
    "Each row of the column is one observation of a single characteristic.\n",
    "Below, we will create a Series to hold the last return of a Stock, and each row will represent the company name:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(data=np.random.random(5), name='returns')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of each row as a return observation for a stock.\n",
    "Or each row as representing a different company, and the characteristic is the return for a month.\n",
    "The Series object can only hold data of a single type.\n",
    "The values of the column are stored in a numpy array:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.values, type(s.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, `s` itself is another class with more features.\n",
    "And only one of its attributes is the numpy array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical operations work as they would with a Numpy array:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s + 1\n",
    "s * 100\n",
    "np.exp(s)\n",
    "np.log(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the series (the column of numbers) serves as a way to find the data we want.\n",
    "But, we can change the way the data is indexed.\n",
    "For example, we can change from numbers to text:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.index)\n",
    "s.index = ['SPY', 'AAPL', 'TSLA', 'AMZN', 'COST']\n",
    "print(s)\n",
    "print(s.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now the type of the index is `object`, instead of `float_`.\n",
    "We can access the rows using the same notation as dictionaries:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['SPY']\n",
    "s['AAPL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But they are more flexible. For example, we can acess multiple rows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[['SPY', 'AAPL']]\n",
    "s[['SPY', 'AAPL', 'COST']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the slicing notation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[:]\n",
    "s[0:2]\n",
    "s[-2:]\n",
    "s[[0, 1, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the in operator to test against the series index:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SPY' in s)\n",
    "print('GOOG' in s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` is a collection of many `Series`.\n",
    "It is like a spreadsheet, where each column represents one variable and each row an observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=np.random.random((5, 3)))\n",
    "# DataFrame does not take a name argument.\n",
    "type(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows are indexed by numbers:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index)\n",
    "df.index = ['SPY', 'AAPL', 'TSLA', 'AMZN', 'COST']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are also indexed by numbers, but we can also change the indexing to represent the characteristics:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "df.columns = ['return', 'last dividend', 'last price']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a DataFrame there are several ways of indexing.\n",
    "However, we need to be careful, since the usual slicing is not valid anymore.\n",
    "The use of brackets is used to access ****columns****:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['return']\n",
    "df['last price']\n",
    "df[['last dividend', 'return']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the DataFrame columns are reordered depending on the order of the columns.\n",
    "\n",
    "Now, to slice rows we use the method `iloc`.\n",
    "You can also use `[]` to slice rows, but that is not the preferred way and might be confusing, since `[]` is mainly used for getting columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, :2]\n",
    "df.iloc[:, -2:]\n",
    "df.iloc[[0, 2], [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `iloc` is for selectin rows and columns by ****integer**** indexing.\n",
    "We can use the `loc` method for selecting rows and columns by ****label****.\n",
    "Labels are the values given to the indices and columns of the `DataFrame`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['AAPL', 'TSLA'], ['return', 'last price']]\n",
    "df.loc['AAPL', 'return']\n",
    "df.loc['AAPL', :]\n",
    "# Get the labels from the index\n",
    "df.index[:2]\n",
    "df.loc[df.index[:2], ['return', 'last dividend']]\n",
    "# Notice that when we select a single column, we get back a Series:\n",
    "type(df.loc[['AAPL', 'TSLA'], 'return'])\n",
    "# The same happens for a single row:\n",
    "type(df.loc['AAPL', :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reading Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also implements several methods for reading data into a `DataFrame`.\n",
    "Let's use `pd.read_csv` to download .csv data and load it into a DataFrame.\n",
    "`pd.read_csv` can read a local file, but can also take a url to read an online file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/python-for-economists/lecture-notes/master/supporting/data/business.csv'\n",
    "data = pd.read_csv(url)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several columns that in the data that we won't use.\n",
    "We can select the only ones we want by indexing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "data.columns[5:]\n",
    "columns_to_keep = ['Economy Name', *list(data.columns[5:])]\n",
    "columns_to_keep\n",
    "data = data[columns_to_keep]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the country name of Korea to South Korea:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1, 0] = 'South Korea'\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the index, so that instead of using numbers, we use the country names:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Economy Name')\n",
    "# a new object is created when we call set_index and a new DataFrame is returned\n",
    "# the original DataFrame was not modified\n",
    "data\n",
    "# But we do want to modify it:\n",
    "data = data.set_index('Economy Name')\n",
    "data\n",
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the name of some columns:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['total_tax', 'profit_tax',\n",
    "                'tax_score', 'electricity_score', 'law_score']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the scores to numbers between 0 and 1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tax_score'] = data['tax_score']/100\n",
    "data['electricity_score'] = data.electricity_score/100\n",
    "data.law_score = data.law_score/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a column with an equally weighted score based on the scores for taxation, electricity and law enforcement.\n",
    "There are a few ways of doing so:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = (data.tax_score + data.electricity_score + data.law_score)/3\n",
    "second = np.sum(data.iloc[:, 2:], axis=1)/3\n",
    "third = data.iloc[:, 2:].mean(axis=1)\n",
    "all(first == second)\n",
    "all(second == third)\n",
    "data['score'] = data[['tax_score', 'electricity_score', 'law_score']].mean(axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is also built on top of Matplotlib.\n",
    "The `Series` and `DataFrame` classes provide methods to automatically plot what is stored in these objects:\n",
    "\n",
    "Create a bar plot with the scores for each country:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data['score'].plot(kind='bar', title='Business Score')\n",
    "ax.set(ylabel='Score (0 to 1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select the data you want to plot, and even do plot each column on a different axis:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data[['score', 'total_tax']].plot(kind='bar', subplots=True, title=['Business Score','Total Taxes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar functionality is available for line and scatter plots.\n",
    "\n",
    "Let's sort the data by the score and re-plot:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by='total_tax', ascending=True)\n",
    "ax = data['total_tax'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Time Series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the module [`requests`](https://2.python-requests.org/en/master/) to obtain financial data from the [Federal Reserve Bank of St. Louis](https://fred.stlouisfed.org).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download US Unemployment Rate\n",
    "url = 'http://research.stlouisfed.org/fred2/series/UNRATE/downloaddata/UNRATE.csv'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Request succeeded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of the csv file is stored in the response:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)\n",
    "# The method decode can help:\n",
    "print(response.content.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store the contents into a local `csv` file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('UNRATE.csv', 'w') as f:\n",
    "    f.writelines(response.content.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the file with an editor.\n",
    "The first row contains the column headers.\n",
    "The first column contains dates for the observations, and we will use it as the index of the DataFrame.\n",
    "The second column contains the unemployment rate.\n",
    "\n",
    "We can use pd.read<sub>csv</sub> to load the data in a `DataFrame`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('UNRATE.csv', index_col=0, parse_dates=True)\n",
    "# If the parse_dates input is True, it tries to parse the values in\n",
    "# the index as dates.\n",
    "type(data)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look a the first rows of the data and at the last rows of the data with the methods `head` and `tail`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some summary statistics:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the number of decimal places PANDAS use:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 1)\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the column name:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['Unemployment Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the time series:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or only a few years:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data['2009':].plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Using an API\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some websites offer an API (application programming interface) that we can use to request data.\n",
    "For example, the [World Bank](https://data.worldbank.org/indicator) makes available several different indicators via their [API](https://datahelpdesk.worldbank.org/knowledgebase/articles/889392-about-the-indicators-api-documentation).\n",
    "The easiest way to work with their API is to go to the [indices page](https://data.worldbank.org/indicator), click on the index you are interested in, and then right-click on the `CSV` button and copy the link (an url).\n",
    "Alternatively, you could click on the `EXCEL` button to get the url for downloading the spreadsheet.\n",
    "Having the url, you can request the data in Python by submitting a get request with the `requests` module.\n",
    "\n",
    "Let's download the GDP per capita series.\n",
    "If you use the download format for `csv` files, you will get back a `.zip` instead.\n",
    "We can deal `.zip` files directly in Python via the built-in [`zipfile`](https://docs.python.org/3/library/zipfile.html) module.\n",
    "For more details read this [stack post](https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url).\n",
    "We will download the Excel file instead:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://api.worldbank.org/v2/en/indicator/NY.GDP.PCAP.CD?downloadformat=excel'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Request succeeded.\")\n",
    "    with open('gdp_capita.xls', 'wb') as f:\n",
    "        # open with the option write binary, since xls is a binary file\n",
    "        f.write(response.content)\n",
    "        print(\"File saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load Excel files in pandas as easy as csv files.\n",
    "You might need to install the `xlrd` package (`pip install xlrd`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('gdp_capita.xls', sheet_name='Data',\n",
    "                     skiprows=3, index_col=1)\n",
    "type(data)\n",
    "# Recover the GDP per capita for Brazil\n",
    "data.columns\n",
    "data.index\n",
    "gdp_brazil = data.loc['BRA', data.columns[3:]]\n",
    "type(gdp_brazil)\n",
    "gdp_brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdp_brazil.plot(kind='line', color='black', grid=True,\n",
    "                     title=\"Brazil's GDP per Capita (in US$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Panel Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Pandas to work with panel data.\n",
    "The OECD makes available [data](https://stats.oecd.org/Index.aspx?DataSetCode=RMW) on real minimum wages of several countries.\n",
    "I have downloaded that data and uploaded to Github, we will download it and store it in a pandas DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/python-for-economists/lecture-notes/master/supporting/data/oecd_real_wage.csv'\n",
    "data = pd.read_csv(url, index_col='Time', parse_dates=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have panel data, we will see several repeats of the same country, at different time periods.\n",
    "Let's first clean the columns and keep only what really matters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need both the country name and the code.\n",
    "The column `Series` describes the two types of wages available, but the name is too long.\n",
    "Let's use the column `SERIES` instead.\n",
    "We can keep the `Pay Period` column since it descibes whether wages are annual or hourly.\n",
    "We also need the `Value` column, since that contains the wages.\n",
    "All the other columns can be thrown away.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Country', 'SERIES', 'Pay period', 'Value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proper way to rename columns is with the method `rename`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'SERIES': 'Series', 'Value': 'Real Wage'},\n",
    "            inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to index our data by the time period.\n",
    "We would also like to divide the data by the country, by the type of the series (USD PPPs or USD exchange rates), and by the type of pay period (annual or hourly).\n",
    "Dividing the data into sub-categories allows us to express multi-dimensional data in a 2-D table!\n",
    "To do so, we need to use a [`pivot_table`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html), which basically breaks down columns (or indices) by several categories:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "data.index\n",
    "data = data.pivot_table(values='Real Wage',\n",
    "                        index='Time',\n",
    "                        columns=['Country', 'Series', 'Pay period'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a table where the index is given by the years, and the columns are split by the country, then by the series, and then by the pay period.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.columns)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [MultiIndex](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html) object is now used to store the columns.\n",
    "One of its attributes is `levels`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns.levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `levels` is a list of lists, where the first element (which is a list) contains the values of the countries, the second list contains the values of the `Series` column, and the third list contains the values of the `Pay period` column.\n",
    "The MultiIndex is a ****hierarchical structure****, and the order it follows was the order that was given in the `pivot_table` function.\n",
    "In this case, the labels first in the hierarchy are the `Country` names, then comes the `Series` names, and last the `Pay period`.\n",
    "\n",
    "We can select columns of the data by using the slicing operator:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Brazil']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above goes into the column of the country Brazil, and displays all the values for this country.\n",
    "We go down 1-level in the hierarchy, and now there are only two divisions for columns, the first is for Series and the second for Pay period.\n",
    "\n",
    "We can get multiple countries as well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Brazil', 'Chile']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we still have the Country hierarchy.\n",
    "\n",
    "We can go deeper in the hierarchy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns.levels\n",
    "data['Brazil']['PPP']\n",
    "data['Brazil']['PPP']['Hourly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slices above can be used to access data in a single columns (or in a single column for each hierarchy level).\n",
    "\n",
    "To get multiple columns, we use the `loc` method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, ['Brazil', 'Chile']]\n",
    "type(data.loc[:, ['Brazil', 'Chile']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, the use of `[]` when slicing defines the columns that we want to get, but only based on the first level of the hierarchy.\n",
    "If we want to go lower in the hierarchy, we need to parentheses (a tuple).\n",
    "A tuple specifies a complete ****multi-level**** key, where each element of the tuple specifies the keys for one level:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, ('Brazil', 'EXR')]\n",
    "data.loc[:, ('Brazil', 'EXR', 'Annual')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the tuple represents the key in one of the levels of the hierarchy.\n",
    "\n",
    "If we also use brackets, then we are defining multiple columns to get at each hierarchy level:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, (['Brazil', 'Chile'], ['EXR'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `:` means we want all rows.\n",
    "Then we have a big tuple `( .... )`.\n",
    "A tuple has a special meaning when being used with a `MultiIndex`.\n",
    "Each element of the tuple is related to each level of the `MultiIndex`.\n",
    "The first element of the tuple is a list: `['Brazil', 'Chile']`.\n",
    "A list has a special meaning when being used with a `MultiIndex`.\n",
    "It species a list of keys in the same hierarchical level to retrieve.\n",
    "In this case, we are telling `loc` to retrieve the columns named `'Brazil'` and `'Chile'`.\n",
    "The second element of the tuple is a list with one element: `['EXR']`.\n",
    "It tells `loc` that, given the choices for the first hierarchical level, it should get the column named `'EXR'` on the second level.\n",
    "\n",
    "We can go lower on the hierarchy and also define the keys for the third level:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc[:, (['Brazil', 'Chile'], ['EXR', 'PPP'], ['Annual'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful method is [`stack`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html).\n",
    "It takes a column name of the `MultiIndex` and shifts it to the row indices.\n",
    "In doing so, it transforms the row index in a `MultiIndex` too!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.stack(level='Country').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the table has a `MultiIndex` for the indices, where the 1st level of the hierarchy is the time period and the second level is the country name.\n",
    "\n",
    "Calling `stack` without any arguments shifts the lowest hierarchy of the columns.\n",
    "In our case, it would shift the `Pay period`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.stack().head()\n",
    "type(data.stack().head().index)\n",
    "# hierarchy\n",
    "data.stack().index.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use numbers instead of labels with stack:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift Country:\n",
    "data.stack(level=(0))\n",
    "# Shift Series\n",
    "data.stack(level=(1))\n",
    "# Shift Pay Period\n",
    "data.stack(level=(2))\n",
    "# We can shift multiple levels:\n",
    "data.stack(level=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a cross-section of the data, we can fix the time period:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['2018'].stack(level=(1, 2))\n",
    "# now the column is back to being a regular Index\n",
    "data.loc['2018'].stack(level=(1, 2)).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the countries names as the main index, we can transpose everything:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['2018'].stack(level=(1, 2)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go further and select only the annual wage and those measured using the purchasing-power parity:\n",
    "We will do this in 2 ways.\n",
    "First, by direct selection of the columns:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csec = data.loc[:, (slice(None), ['PPP'], ['Annual'])]\n",
    "csec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `slice(None)` means that we want to select all of the values of the 1st hierarchical level.\n",
    "\n",
    "We can now drop the `Series` and `Pay period` levels since they are fixed:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csec = csec.droplevel(level=(1, 2), axis=1)\n",
    "csec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, using the `xs` method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(data.xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pass it the key representing the values.\n",
    "We also need to specify `axis=1`, since we are getting the data from columns.\n",
    "And specify what is the hierarchy because we are dealing with `MultiIndex`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csec = data.xs(key=('PPP', 'Annual'), axis=1, level=('Series', 'Pay period')).copy()\n",
    "csec.head()\n",
    "type(csec.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `copy` method because we are going to modify this data.\n",
    "Without the `.copy`, we would be getting back a \"view\" of the data.\n",
    "Pandas tries to be very efficient, so it does not copy data most of the time.\n",
    "This means that slicing returns a \"zoomed in\" version of the table (referred to as a \"view\").\n",
    "If we try to modify a zoomed in version of the table, we will get a warning, because it could affect the rest of the data.\n",
    "We need to copy the data from the zoomed in version of the table so that we get a new table (different space in memory).\n",
    "And this new table we can modify. This was achieved by using the method copy.\n",
    "\n",
    "We can check for missing values with the [`isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html?highlight=isnull) method:\n",
    "Returns `True` if `np.NaN` is found, otherwise it returns `False`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csec.isnull()\n",
    "# Count by column (sum by row):\n",
    "csec.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 14 missing values for Germany and 1 for Japan.\n",
    "\n",
    "Pandas provides a helper function for filling missing values: [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html?highlight=dataframe.fillna#pandas.DataFrame.fillna).\n",
    "We will use the method `'ffill'` to use the last valid value to fill the next missing value:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csec['Japan'].fillna(method='ffill')\n",
    "csec['Japan']\n",
    "csec['Japan'] = csec['Japan'].fillna(method='ffill')\n",
    "csec['Japan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Germany we have too many missing values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csec['Germany']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too many missing values, so we can try going back to the data source and see what happened (maybe an error?)\n",
    "Try to interpolate the data, or simply drop the country.\n",
    "Let's drop the column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csec = csec.drop(labels=['Germany'], axis=1)\n",
    "'Germany' in csec.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Merge, Join and Concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use another data set that contains data on continent names and countries to add a new level to our panel data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/python-for-economists/lecture-notes/master/supporting/data/continent_countries.csv'\n",
    "continents = pd.read_csv(url)\n",
    "continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides several methods of combining different DataFrame and Series objects.\n",
    "We will use the [`merge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html#pandas.merge) method to merge the panel data to the `continents` DataFrame we just loaded.\n",
    "To learn more about `merge`, and about the `join` and `concatenate` methods read the [Method, join and concatenate reference page](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#merge-join-and-concatenate).\n",
    "\n",
    "The `continents` and `csec` have an index in common: the country names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csec\n",
    "continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the country names as a key to merge the two tables, this is known as a one-to-one join.\n",
    "\n",
    "Let's transform the two DataFrame objects so that the column Country is their only row index:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents.head()\n",
    "continents = continents.set_index(keys='Country')\n",
    "continents.head()\n",
    "\n",
    "csec = csec.transpose()\n",
    "csec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two tables, where both of them have as index a column with Country names.\n",
    "Notice that the indices must be unique for this to work.\n",
    "We want to keep all the columns of the `csec` table (each column represents a year) and add the column with the continent names from `continents`.\n",
    "\n",
    "The `merge` method takes the inputs:\n",
    "\n",
    "-   left: the first table;\n",
    "-   right: the second table;\n",
    "-   left<sub>index</sub>: specifies if we want to use the index from the `left` table as the key to merge the two tables;\n",
    "-   how: specify what keys to use when merging the tables. If we are using multiple keys, we can specify to take the union of the keys, or the intersection. In our case, we will use only the country names from the `csec` tables as the key.\n",
    "-   right<sub>index</sub>: specifies if we want to use the index from the `right` table as the key to merge the two tables. In our case, we want this to be True.\n",
    "\n",
    "The keys that we specify on the two tables are the values that will be used to match the values from the tables.\n",
    "By specifying the `how` input as `'left'`, we choose to merge the two tables but keep the keys from the left table as the index, dropping the other keys from the right table that do not have a counterpart on the left table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csec.index.values)\n",
    "len(continents.index.values)\n",
    "merged = pd.merge(left=csec, right=continents, left_index=True, right_index=True, how='left')\n",
    "len(merged.index.values)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an extra column named continent at the end of the table.\n",
    "\n",
    "We need to check for missing values in the new column!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = merged.Continent.isnull()\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a `Series` of boo leans as an index to slice another `Series`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.Continent[missing]\n",
    "countries = merged.Continent[missing].index.values\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korea, Russia and Slovakia are missing continents.\n",
    "\n",
    "We can fix those:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, cont in zip(countries, ['Asia', 'Asia', 'Europe']):\n",
    "    merged.loc[country, 'Continent'] = cont\n",
    "merged.Continent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reset the index so that `Country` becomes a column again:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.reset_index()\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the index so that we split the data by continent and by country:\n",
    "That is, let's create a `MultiIndex` with `Continent` as the first level, and `Country` as the second level:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.set_index(keys=['Continent', 'Country'])\n",
    "merged.head()\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort by the `Continent` index so that the table is easier to visualize:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.sort_index(level='Continent')\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Aggregating Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a nicely formatted panel, we can aggregate and visualize the data.\n",
    "\n",
    "Time average of the wages by country and by continent:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.mean(axis=1)\n",
    "# axis=1: will average across all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series of average wage by Continent:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average across all rows of each Continent\n",
    "merged.mean(axis=0, level='Continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time average of wages by continent:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.mean(axis=0, level='Continent').mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest wage in each continent at each year:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.max(axis=0, level='Continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the columns are times, but there is an issue with the values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type is object, but we want it to be `datetime`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(merged.columns)\n",
    "merged.columns = pd.to_datetime(merged.columns)\n",
    "merged.columns.name = 'Time'\n",
    "merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the correct type for dates allows us to easily slice by year:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest wage on 2018 by continent\n",
    "merged['2018-1-1'].max(axis=0, level='Continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative and more general approach to aggregating data is with the [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby) method.\n",
    "The idea is to split the table into groups (defined by some criteria), then apply a function to each of the groups (group by group), and then combine the results in a table again.\n",
    "\n",
    "Let's compute the time average of the wages by country and by continent:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = merged.groupby('Continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grouped` is a collection of groups.\n",
    "It is basically a dictionary, where each key corresponds to one of the groups defined by the splitting rule.\n",
    "In this case, the rule was to split by Continent, so each key is going to be the name of the continent.\n",
    "We can see each of the groups like so:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, group in grouped:\n",
    "    print(f\"Key: {key}\")\n",
    "    print(f\"Group:\\n {group.head()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply a function to each group to aggregate the values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.mean()\n",
    "# Equivalents:\n",
    "merged.groupby('Continent').mean()\n",
    "merged.mean(axis=0, level='Continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example.\n",
    "Get the number of countries in each group (continent):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.groupby('Continent').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also supply custom functions to aggregate the data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median\n",
    "merged.groupby('Continent').aggregate(np.median)\n",
    "# Compute variance\n",
    "merged.groupby('Continent').aggregate(np.var)\n",
    "# Compute several values at once\n",
    "merged.groupby('Continent').aggregate([np.mean, np.median, np.argmin])\n",
    "# Can choose to apply functions to specific columns\n",
    "merged.groupby('Continent').aggregate({'2017-1-1': np.sum})\n",
    "# Or even different functions per column\n",
    "merged.groupby('Continent').aggregate({'2017-1-1': np.sum,\n",
    "                                       '2018-1-1': np.max})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should read the [Group By reference page](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#group-by-split-apply-combine) for further details.\n",
    "\n",
    "We can use the result of the grouping to plot:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.transpose()\\\n",
    "      .groupby(level='Continent', axis=1)\\\n",
    "      .mean()\\\n",
    "      .plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a bar plot of the time average real minimum wage for the different countries:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_avg = merged.transpose().mean(axis=0)\n",
    "time_avg\n",
    "time_avg = time_avg.droplevel(0)\n",
    "time_avg\n",
    "time_avg.sort_values().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Resampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with data index by time, we can leverage Pandas functions to re-sample our data to different frequencies.\n",
    "What follows is a simple example, but for a more in depth understanding you should read the [Time Series and Date functionality](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html) reference page.\n",
    "\n",
    "Change index to time:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.transpose()\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change frequency to \"year start\":\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.index.freq = 'AS'\n",
    "merged.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas identified all dates started in january, so it appended the `JAN` to reflect that.\n",
    "See the [Frequency (Offset Aliases) reference page](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases) for the possible frequencies.\n",
    "\n",
    "The [`resample`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.resample.html#pandas.Series.resample) method is similar to a group by, but works with time indices.\n",
    "To down-sample to biyearly, while averaging the values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.resample('2AS').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other aggregation methods are available.\n",
    "To down-sample to biyearly, but taking the most recent value instead of the average:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.resample('2AS').first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also up-sample:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample to every month\n",
    "merged.resample('MS').first()\n",
    "# Interpolate to fill the missing values\n",
    "merged.resample('MS').first().interpolate(method='linear')\n",
    "# Use spline to interpolate\n",
    "merged.resample('MS').first().interpolate(method='spline', order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the [`interpolate`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.interpolate.html) function to fill the missing values when upsampling.\n",
    "\n",
    "We can plot to see the interpolation results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled = merged.resample('MS').first().interpolate(method='spline', order=3)\n",
    "# Drop Continent and select Brazil\n",
    "brazil = upsampled.droplevel(0, axis=1)['Brazil']\n",
    "# Plot the values\n",
    "ax = brazil.plot(kind='line', color='green', linewidth=0.5)\n",
    "brazil.resample('YS').first().plot(ax=ax, kind='line', style='.', color='black')\n",
    "ax.legend(['Interpolation (Cubic Spline)', 'Original Data'])\n",
    "ax.grid(True, linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Statsmodels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Statsmodels](https://www.statsmodels.org/stable/index.html) package can be used to estimate several classical statistical models.\n",
    "It is built on top of Pandas and Numpy.\n",
    "We will learn how to use its linear regression tools.\n",
    "\n",
    "Let's start by loading some financial data (Fama-French 3 factors):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/python-for-economists/lecture-notes/master/supporting/data/ff3factors.CSV\"\n",
    "factors = pd.read_csv(url, skiprows=3, index_col=0, parse_dates=True)\n",
    "factors\n",
    "factors.index\n",
    "factors.index = pd.to_datetime(factors.index, format='%Y%m')\n",
    "factors.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also load data for the Apple stock:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/python-for-economists/lecture-notes/master/supporting/data/monthlyAAPL.csv\"\n",
    "stock = pd.read_csv(url, skiprows=0, index_col=0, parse_dates=True)\n",
    "stock = stock['Close']\n",
    "stock.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the arithmetic returns:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = stock.pct_change()\n",
    "returns\n",
    "# convert to returns in percentage\n",
    "returns = 100*returns\n",
    "returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge the Fama-French factors with the monthly returns from Apple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(left=returns, right=factors, left_index=True, right_index=True, how='left')\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute excess stock return:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['Excess Return'] = merged['Close'] - merged['RF']\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with missing observations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.dropna()\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import Statsmodels:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sm` has a class for OLS.\n",
    "We will run a linear regression of stock return on risk-free rate and market excess return\n",
    "First, we build the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(endog=merged['Excess Return'], exog=merged['Mkt-RF'])\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `model` to estimate the parameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit()\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `results` object holds all the estimates and many other statistics.\n",
    "We can visualize all the information at once by calling the summary method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())\n",
    "dir(results)\n",
    "print(results.params)\n",
    "print(results.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` method of `results` can be used to compute $\\hat{y}$ for a given $x$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.predict(exog=[5.3])\n",
    "results.predict(exog=[5.3, -2.3, -10.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the original data and the estimated model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = merged.plot(kind='scatter', x='Mkt-RF',\n",
    "                 y='Excess Return', alpha=0.4, label='observed')\n",
    "ax.scatter(merged['Mkt-RF'], results.predict(),\n",
    "           color='k', alpha=0.6, label='predicted')\n",
    "ax.set(title='Predicted Monthly Excess Return from Regression',\n",
    "       xlabel='Market Excess Return (in %)',\n",
    "       ylabel='Stock Excess Return (in %)')\n",
    "ax.legend()\n",
    "ax.grid(True, linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the regression with the other factors, one by one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = sm.OLS(endog=merged['Excess Return'],\n",
    "                exog=merged[['Mkt-RF', 'HML']])\n",
    "model3 = sm.OLS(endog=merged['Excess Return'],\n",
    "                exog=merged[['Mkt-RF', 'HML', 'SMB']])\n",
    "results2 = model2.fit()\n",
    "results3 = model3.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the results of several regressions we can use a helper function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.iolib.summary2 import summary_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`summary_col` takes a list of objects representing different OLS results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_col([results, results2, results3], float_format='%.2f',\n",
    "            model_names=('CAPM', 'FF 2 Factors', 'FF 3 Factors'),\n",
    "            stars=True, regressor_order=['Mkt-RF', 'HML', 'SMB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To also display the R-squared and other statistics we need to use the `info=_dict input.\n",
    "=info_dict` is a dict, where the keys will be used a labels for the rows and the values are functions that extract the values from the regression results object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {'R-squared': lambda r: f\"{r.rsquared:.2f}\",\n",
    "             'Total Observations': lambda r: f\"{r.nobs:.0f}\"}\n",
    "summary_col([results, results2, results3], float_format='%.2f',\n",
    "            model_names=('CAPM', 'FF 2 Factors', 'FF 3 Factors'),\n",
    "            stars=True, regressor_order=['Mkt-RF', 'HML', 'SMB'],\n",
    "            info_dict=info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these summary functions generate tables.\n",
    "You can store the tables in a variable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = summary_col([results, results2, results3], float_format='%.2f',\n",
    "            model_names=('CAPM', 'FF 2 Factors', 'FF 3 Factors'),\n",
    "            stars=True, regressor_order=['Mkt-RF', 'HML', 'SMB'],\n",
    "            info_dict=info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And one of the methods of the table is exporting to latex:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(table)\n",
    "print(table.as_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you also install the [Pyperclip](https://github.com/asweigart/pyperclip) package:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyperclip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can automatically copy the table to the clipboard and then you can simply paste it into your latex files:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "pyperclip.copy(table.as_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statsmodels is not limited to linear regressions, and also provides functions for estimating:\n",
    "\n",
    "-   [Generalized Linear Models](https://www.statsmodels.org/stable/glm.html)\n",
    "-   [Generalized Estimating Equations](https://www.statsmodels.org/stable/gee.html)\n",
    "-   [Generalized Additive Models](https://www.statsmodels.org/stable/gam.html)\n",
    "-   [Robust Linear Models](https://www.statsmodels.org/stable/rlm.html)\n",
    "-   [Linear Mixed Effects Models](https://www.statsmodels.org/stable/mixed_linear.html)\n",
    "-   [Regression with Discrete Dependent Variable](https://www.statsmodels.org/stable/discretemod.html)\n",
    "-   [Generalized Linear Mixed Effects Models](https://www.statsmodels.org/stable/mixed_glm.html)\n",
    "-   [ANOVA](https://www.statsmodels.org/stable/anova.html)\n",
    "-   [Time Series](https://www.statsmodels.org/stable/tsa.html)\n",
    "-   [Vector Autoregression](https://www.statsmodels.org/stable/vector_ar.html)\n",
    "-   [Survival and Duration Analysis](https://www.statsmodels.org/stable/duration.html)\n",
    "-   [Nonparametric Methods](https://www.statsmodels.org/stable/nonparametric.html)\n",
    "-   [Generalized Method of Moments](https://www.statsmodels.org/stable/gmm.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
